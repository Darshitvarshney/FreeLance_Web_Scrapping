# FreeLance_Web_Scrapping

# ğŸ“Š Google Maps Business Data Scraper

## Project Overview

This project is a high-performance web scraping solution designed to extract structured business data from **Google Maps** at a city and state level.
It automates the collection of business information such as:

* Business Name
* Address
* Phone Number
* Website
* Email (if available)
* Google Maps URL
* Latitude & Longitude

The scraper is optimized for **scalability**, **accuracy**, and **export-ready datasets** (Excel format).

---

## âš™ï¸ Technology Stack

* Python 3.9+
* Playwright (browser automation)
* aiohttp (async HTTP requests)
* asyncio (concurrency management)
* pandas (data processing)
* openpyxl (Excel export)

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ main.py         # Version 1 â€“ Deep extraction (slow but very thorough)
â”œâ”€â”€ main_final.py   # Version 2 â€“ Optimized high-speed scraper
â”œâ”€â”€ combine.py      # Utility script to merge multiple Excel outputs
â”œâ”€â”€ USA_Cities_2025_New.xlsx
```

---

## ğŸš€ main.py (Version 1 â€“ Deep Extraction Engine)

**Purpose:**
Designed for **maximum data completeness**.

**Characteristics:**

* Sequential scraping logic
* Performs deeper page interaction
* Uses higher wait times for element detection
* Safer for dynamic pages
* Best suited for:

  * Small datasets
  * High-value leads
  * When accuracy is prioritized over speed

**Advantages:**

* More stable
* Higher chance of capturing missing fields
* Minimal risk of partial data

**Limitation:**

* Slower execution due to conservative timeouts and reduced concurrency

---

## âš¡ main_final.py (Version 2 â€“ High-Speed Production Scraper)

**Purpose:**
Built for **large-scale data collection** with performance optimization.

**Enhancements:**

* Parallel city scraping using asyncio
* Parallel business scraping using semaphores
* Resource blocking (images, fonts, media, CSS)
* Reduced timeouts
* Batched Excel exports
* Resume support using progress file

**Advantages:**

* 3â€“5x faster than Version 1
* Suitable for:

  * State-level scraping
  * Large datasets
  * Commercial lead generation
* Automatically saves progress
* Handles crashes and restarts gracefully

**Trade-off:**

* Slightly less aggressive extraction than Version 1
* Optimized for **speed + sufficient data coverage**

---

## ğŸ“¤ Output Format

Each run generates Excel files where:

* Each city is stored as a separate sheet
* Columns:

  ```
  Name | Address | Phone | Website | Email | Google Maps URL | Latitude | Longitude
  ```
* Files are timestamped for traceability

---

## ğŸ§© combine.py (Data Merger)

This script:

* Combines multiple state or batch Excel files
* Removes duplicates using Google Maps URL
* Produces a single consolidated workbook

Used after scraping is complete for final dataset delivery.

---

## â–¶ï¸ How to Run

### Install dependencies:

```bash
pip install playwright aiohttp pandas openpyxl
playwright install
```

### Run Version 1 (Deep Mode):

```bash
python main.py
```

### Run Version 2 (Fast Mode):

```bash
python main_final.py
```

### Merge Output Files:

```bash
python combine.py
```

---

## ğŸ“Œ Use Case

* Lead generation
* Market research
* Business intelligence
* Location-based analytics
* Freelance data delivery

---

## ğŸ§  Development Philosophy

This project was developed in **two stages**:

1. **main.py** â€“ Accuracy-first prototype
2. **main_final.py** â€“ Speed-optimized production build

This ensures both:

* Data integrity
* Operational efficiency

---

## ğŸ“„ License & Usage

This codebase is provided as part of a freelance project and is intended for controlled, ethical, and compliant web scraping.



